cd
cd fvcom/_run

# SINGLE HOST TEST
# mpirun --bind-to core --mca btl self,vader ./fvcom --CASENAME=wvi_inlets4



# AWS with UCX
fi_info -p efa
mpirun --bind-to core --hostfile ~/hosts -mca pml ucx -mca btl ^uct -x UCX_NET_DEVICES=mlx5_0:1 ./fvcom --CASENAME=wvi_inlets4
mpirun --bind-to core --hostfile ~/hosts -mca pml ucx ./fvcom --CASENAME=wvi_inlets4
mpirun --bind-to core --hostfile ~/hosts ./fvcom --CASENAME=wvi_inlets4
mpirun --bind-to core -mca pml ucx -mca btl ^uct -x UCX_NET_DEVICES=mlx5_0:1 ./fvcom --CASENAME=wvi_inlets4

# AWS pingpong
mpirun --bind-to core --hostfile ~/hosts ./IMB-MPI1 pingpong

mpirun --hostfile ~/hosts --mca btl self,tcp ./IMB-MPI1 pingpong



# This one cuts in half (F* series)
# mpirun -N $(($(nproc)/2)) --hostfile ~/hosts --mca btl self,vader,tcp ./fvcom --CASENAME=wvi_inlets4

# Run all cores (Hc44rs)
# mpirun -N $(nproc) --hostfile ~/hosts --mca btl self,vader,tcp ./fvcom --CASENAME=wvi_inlets4

# Bind options
# --bind-to numa
# --bind-to core
# --bind-to socket

# f16 - scaling is perfect with 1node vs 2node. --oversubscribe helps a little bit, not much.

# mpirun -N 32 --mca btl self,vader,tcp ./fvcom --CASENAME=wvi_inlets4
# mpirun -N $(($(nproc)/2)) --hostfile ~/hosts --mca btl self,vader,tcp ./fvcom --CASENAME=wvi_inlets4
# mpirun --bind-to numa --hostfile ~/hosts --mca btl self,vader,tcp ./fvcom --CASENAME=wvi_inlets4
# mpirun --bind-to core --mca btl self,vader,tcp ./fvcom --CASENAME=wvi_inlets4

# 8 nodes, f64
# no parameters, 0.06
# bind to NUMA, 0.058
# bind to CORE, 0.61
# bind to SOCKET , 0.61

# 2 nodes, f72
# no params, 0.072
# bind to NUMA, 0.072

# 2 nodes, hc44rs, tcp
# bind to NUMA, 0.082